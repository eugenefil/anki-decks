#separator:tab
#html:true
#guid column:1
#notetype column:2
#deck column:3
#tags column:6
n]^+[.K6l,	Basic	Math-for-3d-gameprog	Vec decomposition into par and perp components	Decompose \(\vec P\) into components \(par\) and \(perp\) that are correspondingly parallel and perpendicular to \(\vec Q\).<br><br>To get \(par\), we project \(\vec P\) onto \(\vec Q\) and multiply that by a unit vec in the dir of \(\vec Q\):<br>\(par = \|\vec P\| \cos \alpha \frac{\vec Q}{\|\vec Q\|}\)<br>Using dot product:<br>\(\|\vec P\| \cos \alpha = \frac{\vec P \cdot \vec Q}{\|\vec Q\|}\)<br>\(par = \frac{\vec P \cdot \vec Q}{\|\vec Q\|^2} \vec Q\)<br><br>\(\vec P\) is the sum of \(par\) and \(perp\) components:<br>\(\vec P = par + perp\)<br>\(perp = \vec P - par = \vec P - \frac{\vec P \cdot \vec Q}{\|\vec Q\|^2} \vec Q\)<br><br>\(par\) can be rewritten as:<br>\(par = \frac{1}{\|\vec Q\|^2} (P_xQ_x + P_yQ_y + P_zQ_z) \vec Q\)<br>Multiplying by \(\vec Q\) coords gives column-vec:<br>\(par = \frac{1}{\|\vec Q\|^2}<br>\begin{bmatrix}<br>P_xQ^2_x + P_yQ_xQ_y + P_zQ_xQ_z \\<br>P_xQ_xQ_y + P_yQ^2_y + P_zQ_yQ_z \\<br>P_xQ_xQ_z + P_yQ_yQ_z + P_zQ^2_z \\<br>\end{bmatrix}\)<br>Factoring out \(\vec P\):<br>\(par = \frac{1}{\|\vec Q\|^2}<br>\begin{bmatrix}<br>Q^2_x & Q_xQ_y & Q_xQ_z \\<br>Q_xQ_y & Q^2_y & Q_yQ_z \\<br>Q_xQ_z & Q_yQ_z & Q^2_z \\<br>\end{bmatrix}<br>\begin{bmatrix}<br>P_x \\<br>P_y \\<br>P_z \\<br>\end{bmatrix}\)	
qIgdoJLr*X	Basic	Math-for-3d-gameprog	Scalar product properties	1. \(\vec P \cdot \vec Q = \vec Q \cdot \vec P\), commutative<br>2. \((a\vec P) \cdot \vec Q = a (\vec P \cdot \vec Q) \), associative wrt scalar multiplication<br>3. \(\vec P \cdot (\vec Q + \vec R) = \vec P \cdot \vec Q + \vec P \cdot \vec R\), distributive wrt addition<br>4. \(\vec P \cdot \vec P = \|\vec P\|^2\)<br>5. \(\vec P \cdot \vec Q \le \|\vec P\| \|\vec Q\|\), b/c \(\cos \alpha \le 1\)	
OYm_IM_Q^C	Basic	Math-for-3d-gameprog	Cross product as pseudodeterminant and as linear transformation	\(\vec P \times \vec Q = <br>\begin{vmatrix}<br>\vec i & \vec j & \vec k \\<br>P_x & P_y & P_z \\<br>Q_x & Q_y & Q_z \\<br>\end{vmatrix} =\)<br>\(= \vec i (P_yQ_z - P_zQ_y) - \)<br>\(- \vec j (P_xQ_z - P_zQ_x) + \)<br>\(+ \vec k (P_xQ_y - P_yQ_x)\)<br><br>Simplifying gives column-vec:<br>\(\vec P \times \vec Q =<br>\begin{bmatrix}<br>P_yQ_z - P_zQ_y \\<br>P_zQ_x - P_xQ_z \\<br>P_xQ_y - P_yQ_x \\<br>\end{bmatrix}\)<br><br>The above could rewritten as linear transformation:<br>\(\vec P \times \vec Q =<br>\begin{bmatrix}<br>0 \cdot Q_x - P_zQ_y + P_yQ_z \\<br>P_zQ_x + 0 \cdot Q_y - P_xQ_z \\<br> -P_yQ_x + P_xQ_y + 0 \cdot Q_z \\<br>\end{bmatrix} =\)<br>\(=\begin{bmatrix}<br>0 & -P_z & P_y \\<br>P_z & 0 & -P_x \\<br> -P_y & P_x & 0 \\<br>\end{bmatrix}<br>\begin{bmatrix}<br>Q_x \\<br>Q_y \\<br>Q_z \\<br>\end{bmatrix}\)	
f%GNxaPi?5	Basic	Math-for-3d-gameprog	Cross product vector and its geometric interpretation. Triangle square via cross product of its vectors	\(\vec P \times \vec Q\) is perpendicular to both \(\vec P\) and \(\vec Q\). The direction is determined by the right hand rule (or right-handed screw).<br><br>The length of the cross product vec:<br>\(\|\vec P \times \vec Q\| = \|\vec P\| \|\vec Q\| \sin \alpha\)<br><br>Geometrically, the length of the cross product vec equals the area of a parallelogram built on \(\vec P\) and \(\vec Q\). This is easily proved by summing areas of 2 right triangles and the centre rect of that parallelogram:<br><br>\(S = \frac{1}{2} \|\vec P\| \sin \alpha \|\vec P\| \cos \alpha +\)<br>\(+ (\|\vec Q\| - \|\vec P\| \cos \alpha) \|\vec P\| \sin \alpha +\)<br>\(+ \frac{1}{2} \|\vec P\| \sin \alpha \|\vec P\| \cos \alpha\)<br>\(= \|\vec P\| \|\vec Q\| \sin \alpha\)<br><br>As a corollary, triangle square equals half the cross product of the vectors it is built on, b/c that triangle makes half of the parallelogram. E.g. for points A, B, and C represented by their vecs, the area of the triangle:<br>\(S = \frac{1}{2} \|(\vec B - \vec A) \times (\vec C - \vec A)\|\)	
N&Q4JB?&pQ	Basic	Math-for-3d-gameprog	Cross product properties	1. \(\vec P \times \vec Q = -(\vec Q \times \vec P)\), anticommutative<br>2. \((a\vec P) \times \vec Q = a(\vec P \times \vec Q)\), associative wrt scalar multiplication<br>3. \(\vec P \times (\vec Q + \vec R) = \vec P \times \vec Q + \vec P \times \vec R\), distributive wrt addition<br>4. \(\vec P \times \vec P = \vec 0\), b/c \(\sin 0 = 0\)<br>5. \((\vec P \times \vec Q) \cdot \vec R = (\vec R \times \vec P) \cdot \vec Q =\)<br>\(= (\vec Q \times \vec R) \cdot \vec P\)<br>6. \(\vec P \times (\vec Q \times \vec P) = \vec P \times \vec Q \times \vec P =\)<br>\(P^2\vec Q - (\vec P \cdot \vec Q)\vec P\)<br><br>Wrt prop 5, unit vecs \(\vec i\), \(\vec j\), \(\vec k\) in cross product's pseudodeterminant can be replaced with coords of vec \(\vec R\) which results in a proper determinant:<br>\(\begin{vmatrix}<br>R_x & R_y & R_z \\<br>P_x & P_y & P_z \\<br>Q_x & Q_y & Q_z \\<br>\end{vmatrix} =\)<br>\(= R_x(P_yQ_z - P_zQ_y) +\)<br>\(+ R_y(P_zQ_x - P_xQ_z) + \)<br>\(+ R_z(P_xQ_y - P_yQ_x) =\)<br>\((\vec P \times \vec Q) \cdot \vec R\)<br>This determinant is equal to the one below where vec \(\vec R\) is in the bottom b/c the signs in the third row are the same as in the first row:<br>\(\begin{vmatrix}<br>P_x & P_y & P_z \\<br>Q_x & Q_y & Q_z \\<br>R_x & R_y & R_z \\<br>\end{vmatrix} = (\vec Q \times \vec R) \cdot \vec P\)<br>But putting \(\vec R\) in the middle row flips the sign of the result so we have to balance that by flipping rows of \(\vec P\) and \(\vec Q\):<br>\(\begin{vmatrix}<br>Q_x & Q_y & Q_z \\<br>R_x & R_y & R_z \\<br>P_x & P_y & P_z \\<br>\end{vmatrix} = (\vec R \times \vec P) \cdot \vec Q\)<br><br>The 1st part of prop 6 is proved through anticommutativity and associativity:<br>\(\vec P \times (\vec Q \times \vec P) =\)<br>\(= \vec P \times -(\vec P \times \vec Q) =\)<br>\(= -(-(\vec P \times \vec Q) \times \vec P) =\)<br>\(= \vec P \times \vec Q \times \vec P\)	
mAX(vzQ)JZ	Basic	Math-for-3d-gameprog	Vector space. n-dimensional vector space R^n	A vector space is a set of vectors \(V\) for which addition and scalar multiplication are defined and the following properties hold:<br><br>8 props = 2 closures + 2 elements + 2 associativities + 2 distributivities<br><br>1. \(V\) is closed under addition: for each pair of vecs \(\vec P\) and \(\vec Q\) their sum \(\vec P + \vec Q\) is also a vec in \(V\).<br><br>2. \(V\) is closed under scalar mult: for each real scalar \(a\) and vec \(\vec P\) their product \(a\vec P\) is also a vec in \(V\).<br><br>3. There's a zero vec \(\vec 0\) in \(V\) such that for each vec \(\vec P\) its sum \(\vec P + \vec 0 = \vec 0 + \vec P = \vec P\)<br><br>4. There's an additive inverse vec \(\vec Q\) for each vec \(\vec P\) such that \(\vec P + \vec Q = \vec 0\)<br><br>5. Addition is associative: \((\vec P + \vec Q) + \vec R = \vec P + (\vec Q + \vec R)\)<br><br>6. Scalar mult is associative: \((ab)\vec P = a(b\vec P)\)<br><br>7. Scalar mult distributivity over vec addition: \(a(\vec P + \vec Q) = a\vec P + a\vec Q\)<br><br>8. Scalar addition distributivity over scalar mult: \((a + b)\vec P = a\vec P + b\vec P\)<br><br>A vector space can consist of any kind of element provided the props hold. A particular kind of vec space where elements are tuples of \(n\) real numbers is the \(n\)-dimensional vec space \(\mathbb{R}^n\). E.g. \(\mathbb{R}^3\) is the 3D vec space.	
c|pn-)Z?lh	Basic	Math-for-3d-gameprog	Linearly independent vecs. Examples: 2 vecs, 3 vecs	A set of vecs \(\{\vec e_1, \vec e_2, \ldots, \vec e_n\}\) is linearly independent if there are no real numbers \(a_1, a_2, \ldots, a_n\), where at least one of which is non-zero, such that<br>\(a_1\vec e_1 + a_2\vec e_2 + \ldots + a_n\vec e_n = \vec 0\)<br>In other words, vecs are linearly independent if no one vec can be represented as a linear combination of the others.<br><br>This means, no 2 vecs from the set can be collinear b/c otherwise you can obtain one by multiplying the other. As a corollary, 2 non-collinear vecs are linearly independent.<br><br>Also, no 3 vecs from the set can lie on the same plane b/c from a pair of non-collinear vecs you can obtain any 3rd vec on the _same_ plane as a linear combination. But you can't obtain a 3rd vec on any other plane that does not coincide with the plane of the first 2 vecs. Thus, 3 non-collinear vecs not all lying on the same plane are linearly independent.	
"DEO-=?PDQ#"	Basic	Math-for-3d-gameprog	Linear independence of 2 orthogonal vecs, n orthogonal vecs	2 non-zero orthogonal vecs are always linearly independent: if \(\vec e_1 \cdot \vec e_2 = 0\) then there are _no_ two non-zero real numbers \(a_1\) and \(a_2\) such that \(a_1\vec e_1 + a_2\vec e_2 = \vec 0\).<br><br>If there were such numbers \(a_1\) and \(a_2\), then \(\vec e_1 = -\frac{a_2}{a_1}\vec e_2\).<br>Then \(\vec e_1 \cdot \vec e_2 = -\frac{a_2}{a_1}\vec e_2 \cdot \vec e_2 =\)<br>\(= -\frac{a_2}{a_1}e^2_2 \neq 0\)<br>Which contradicts that \(\vec e_1 \cdot \vec e_2 = 0\).<br><br>In simple words: 2 vecs are linearly independent if they are non-collinear and 2 orthogonal vecs is just a special case of that.<br><br>You can do the same for 3 non-zero pair-wise orthogonal vecs \(\vec e_1\), \(\vec e_2\), \(\vec e_3\) and show that they are also linearly independent. I.e. if \(\vec e_1 \cdot \vec e_2 = 0\), \(\vec e_1 \cdot \vec e_3 = 0\) and \(\vec e_2 \cdot \vec e_3 = 0\), then \(\vec e_1\), \(\vec e_2\), \(\vec e_3\) are linearly independent.<br><br>In simple words: 3 vecs are linearly independent if they are non-collinear and don't all lie on the same plane. 3 pairwise orthogonal vecs is just a special case of that.<br><br>In general, \(n\) pairwise orthogonal vecs are linearly independent.	
D$1tbp+2Hm	Basic	Math-for-3d-gameprog	Basis. Number of vecs in basis. Orthogonal basis. Orthonormal basis.	An \(n\)-dim vec space can be generated by a set of \(n\) linearly independent vecs which is called its basis.<br><br>A basis \(B\) for a vec space \(V\) is a set of \(n\) linearly independent vecs \(\{\vec e_1, \vec e_2, \ldots, \vec e_n\}\) for which, given any vec \(\vec P\) in \(V\), there exist real numbers \(a_1, a_2, \ldots, a_n\) such that:<br>\(\vec P = a_1\vec e_1 + a_2\vec e_2 + \ldots + a_n\vec e_n\)<br>In other words, any vec in \(V\) can be represented as a linear combination of basis vecs.<br><br>A basis of an \(n\)-dim vec space consists of _exactly_ \(n\) vecs.<br>E.g. for 3d space:<br>- With 2 basis vecs you can represent any other vec that lies on the _same_ plane. Vecs that don't lie on the basis plane can't be represented, i.e. 2 vecs are not sufficient for 3d.<br>- With 4 vecs in basis, the 4th vec can be represented as a linear combination of the other 3, i.e. any 4 vecs are not linearly independent.<br><br>A basis where all vecs are pairwise orthogonal is called orthogonal basis. Any \(n\) orthogonal vecs are linearly independent (see linear independence card) and thus form a basis for \(n\)-dim vec space.<br><br>An orthogonal basis where each vec has a unit length is called orthonormal basis.<br>Formally, basis \(B = \{\vec e_1, \vec e_2, \ldots, \vec e_n\}\) is orthonormal if for every pair \(i, j\) we have \(\vec e_i \cdot \vec e_j = \delta_{ij}\), where<br>\(\delta_{ij} =<br>\begin{cases}<br>1, & \text{if } i = j \\<br>0, & \text{if } i \ne j \\<br>\end{cases}\)<br>E.g. standard basis \(\{\vec i, \vec j, \vec k\}\) is orthonormal, but also vecs \(\langle \frac{1}{\sqrt 2}, \frac{1}{\sqrt 2}, 0 \rangle\), \(\langle \frac{1}{\sqrt 2}, -\frac{1}{\sqrt 2}, 0 \rangle\) and \(\langle 0, 0, 1 \rangle\).	
x<$cR]{,~5	Basic	Math-for-3d-gameprog	Gram-Schmidt orthogonalization	Gram-Schmidt converts a set of \(n\) arbitrary linearly independent vecs into a set of pair-wise orthogonal. A set of \(n\) pair-wise orthogonal vecs are always linearly independent (see linear independence card).<br><br>Any vec can be decomposed into a sum of 2 components wrt some other vec (see vec decomposition card): parallel (projection) and perpendicular. When you subtract the projection, only perp component remains. This is the essence of orthogonalization.<br><br>Formally, from a set \(B = \{\vec e_1, \vec e_2, \ldots \vec e_n\}\) G-S produces new orthogonal set \(B^* = \{\vec e^*_1, \vec e^*_2, \ldots \vec e^*_n\}\) with the algo:<br><br>1. Set \(\vec e^*_1 = \vec e_1\). The 1st vec taken as is.<br><br>2. Set \(i = 2\).<br><br>3. Take \(\vec e_i\) and subtract from it projections onto all already orthogonal vecs from \(B^*\) leaving only the perp component:<br>\(\vec e^*_i = \vec e_i - \sum^{i - 1}_{k = 1} \frac{\vec e_i \cdot \vec e^*_k}{\|\vec e^*_k\|^2} \vec e^*_k\)<br><br>4. If \(i < n\), increment \(i\) and go to step 3 to convert the next vec from \(B\).<br><br>E.g. for 3d we have roughly:<br><br>1. Set \(\vec e_1\) as \(\vec e^*_1\).<br><br>2. Subtract from \(\vec e_2\) its par projection onto \(\vec e^*_1\) and save as \(\vec e^*_2\). Now both are orthogonal.<br><br>3. \(\vec e^*_1\) and \(\vec e^*_2\) form a plane. \(\vec e_3\) does not lie in that plane, otherwise vecs in \(B\) would _not_ be linearly independent (see linear independence card). Thus \(\vec e_3\) can be decomposed into a sum of a projection onto that plane and a perp component. The projection onto the plane, in turn, can be decomposed into a sum of projections of \(\vec e_3\) onto both \(\vec e^*_1\) and \(\vec e^*_2\). By subtracting those 2 projections from \(\vec e_3\) we're left only with the component perp to both \(\vec e^*_1\) and \(\vec e^*_2\) b/c it's perp to the plane they form.	
LEf?ecYh4@	Basic	Math-for-3d-gameprog	Matrix properties. Matrix vector space	1. Commutativity<br>\(F + G = G + H\)<br><br>2. Associativity of addition<br>\((F + G) + H = F + (G + H)\)<br><br>3. Associativity of scalar mult<br>\((ab)F = a(bF)\)<br><br>4. Distributivity of scalar mult over addition<br>\(a(F + G) = aF + aG\)<br><br>5. Distributivity of scalar addition over scalar mult<br>\((a + b)F = aF + bF\)<br><br>Due to the above props, all matrices of size \(m√ón\) form a vec space (see vector space card).<br><br>6. Associativity of scalar mult wrt matrix mult<br>\((aF)G = a(FG)\)<br><br>7. Associativity of matrix mult<br>\((FG)H = F(GH)\)<br><br>8. Transpose of matrix mult<br>\((FG)^T = G^T F^T\)	
